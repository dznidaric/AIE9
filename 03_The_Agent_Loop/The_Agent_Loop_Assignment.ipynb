{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Agent Loop: Building Production Agents with LangChain 1.0\n",
    "\n",
    "In this notebook, we'll explore the foundational concepts of AI agents and learn how to build production-grade agents using LangChain's new `create_agent` abstraction with middleware support.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what an \"agent\" is and how the agent loop works\n",
    "- Learn the core constructs of LangChain (Runnables, LCEL)\n",
    "- Master the `create_agent` function and middleware system\n",
    "- Build an agentic RAG application using Qdrant\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** Introduction to LangChain, LangSmith, and `create_agent`\n",
    "  - Task 1: Dependencies\n",
    "  - Task 2: Environment Variables\n",
    "  - Task 3: LangChain Core Concepts (Runnables & LCEL)\n",
    "  - Task 4: Understanding the Agent Loop\n",
    "  - Task 5: Building Your First Agent with `create_agent()`\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Create a Custom Tool\n",
    "\n",
    "- **Breakout Room #2:** Middleware - Agentic RAG with Qdrant\n",
    "  - Task 6: Loading & Chunking Documents\n",
    "  - Task 7: Setting up Qdrant Vector Database\n",
    "  - Task 8: Creating a RAG Tool\n",
    "  - Task 9: Introduction to Middleware\n",
    "  - Task 10: Building Agentic RAG with Middleware\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Enhance the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ¤ Breakout Room #1\n",
    "## Introduction to LangChain, LangSmith, and `create_agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "First, let's ensure we have all the required packages installed. We'll be using:\n",
    "\n",
    "- **LangChain 1.0+**: The core framework with the new `create_agent` API\n",
    "- **LangChain-OpenAI**: OpenAI model integrations\n",
    "- **LangSmith**: Observability and tracing\n",
    "- **Qdrant**: Vector database for RAG\n",
    "- **tiktoken**: Token counting for text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install dependencies (if not using uv sync)\n",
    "# !pip install langchain>=1.0.0 langchain-openai langsmith langgraph qdrant-client langchain-qdrant tiktoken nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We need to set up our API keys for:\n",
    "1. **OpenAI** - For the GPT-5 model\n",
    "2. **LangSmith** - For tracing and observability (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing enabled. Project: AIE9 - The Agent Loop - 897a3674\n"
     ]
    }
   ],
   "source": [
    "# Optional: Set up LangSmith for tracing\n",
    "# This provides powerful debugging and observability for your agents\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - The Agent Loop - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key (press Enter to skip): \") or \"\"\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    print(\"LangSmith tracing disabled\")\n",
    "else:\n",
    "    print(f\"LangSmith tracing enabled. Project: {os.environ['LANGCHAIN_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: LangChain Core Concepts\n",
    "\n",
    "Before diving into agents, let's understand the fundamental building blocks of LangChain.\n",
    "\n",
    "### What is a Runnable?\n",
    "\n",
    "A **Runnable** is the core abstraction in LangChain - think of it as a standardized component that:\n",
    "- Takes an input\n",
    "- Performs some operation\n",
    "- Returns an output\n",
    "\n",
    "Every component in LangChain (models, prompts, retrievers, parsers) is a Runnable, which means they all share the same interface:\n",
    "\n",
    "```python\n",
    "result = runnable.invoke(input)           # Single input\n",
    "results = runnable.batch([input1, input2]) # Multiple inputs\n",
    "for chunk in runnable.stream(input):       # Streaming\n",
    "    print(chunk)\n",
    "```\n",
    "\n",
    "### What is LCEL (LangChain Expression Language)?\n",
    "\n",
    "**LCEL** allows you to chain Runnables together using the `|` (pipe) operator:\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "result = chain.invoke({\"query\": \"Hello!\"})\n",
    "```\n",
    "\n",
    "This is similar to Unix pipes - the output of one component becomes the input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see LCEL in action with a simple example\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create our components (each is a Runnable)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that speaks like a pirate.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain them together with LCEL\n",
    "pirate_chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, that be Paris!\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain\n",
    "response = pirate_chain.invoke({\"question\": \"What is the capital of France?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Understanding the Agent Loop\n",
    "\n",
    "### What is an Agent?\n",
    "\n",
    "An **agent** is a system that uses an LLM to decide what actions to take. Unlike a simple chain that follows a fixed sequence, an agent can:\n",
    "\n",
    "1. **Reason** about what to do next\n",
    "2. **Take actions** by calling tools\n",
    "3. **Observe** the results\n",
    "4. **Iterate** until the task is complete\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "The core of every agent is the **agent loop**:\n",
    "\n",
    "```\n",
    "                          AGENT LOOP                         \n",
    "                                                             \n",
    "      +----------+     +----------+     +----------+         \n",
    "      |  Model   | --> |   Tool   | --> |  Model   | --> ... \n",
    "      |   Call   |     |   Call   |     |   Call   |         \n",
    "      +----------+     +----------+     +----------+         \n",
    "           |                                  |              \n",
    "           v                                  v              \n",
    "      \"Use search\"                   \"Here's the answer\"     \n",
    "```\n",
    "\n",
    "1. **Model Call**: The LLM receives the current state and decides whether to:\n",
    "   - Call a tool (continue the loop)\n",
    "   - Return a final answer (exit the loop)\n",
    "\n",
    "2. **Tool Call**: If the model decides to use a tool, the tool is executed and its output is added to the conversation\n",
    "\n",
    "3. **Repeat**: The loop continues until the model decides it has enough information to answer\n",
    "\n",
    "### Why `create_agent`?\n",
    "\n",
    "LangChain 1.0 introduced `create_agent` as the new standard way to build agents. It provides:\n",
    "\n",
    "- **Simplified API**: One function to create production-ready agents\n",
    "- **Middleware Support**: Hook into any point in the agent loop\n",
    "- **Built on LangGraph**: Uses the battle-tested LangGraph runtime under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Building Your First Agent with `create_agent()`\n",
    "\n",
    "Let's build a simple agent that can perform calculations and tell the time.\n",
    "\n",
    "### Step 1: Define Tools\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools created:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for any math ca...\n",
      "  - get_current_time: Get the current date and time. Use this when the user asks a...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool belt\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "print(\"Tools created:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Agent\n",
    "\n",
    "Now we use `create_agent` to build our agent. The function takes:\n",
    "- `model`: The LLM to use (can be a string like `\"gpt-5\"` or a model instance)\n",
    "- `tools`: List of tools the agent can use\n",
    "- `prompt`: Optional system prompt to customize behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create our first agent\n",
    "simple_agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can perform calculations and tell the time. Always explain your reasoning.\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(simple_agent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run the Agent\n",
    "\n",
    "The agent is a Runnable, so we can invoke it like any other LangChain component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "25 Ã— 48 = 1200.\n",
      "\n",
      "Reasoning:\n",
      "- 25 Ã— 48 = 25 Ã— (50 âˆ’ 2) = 25Ã—50 âˆ’ 25Ã—2 = 1250 âˆ’ 50 = 1200.\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a simple calculation\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 25 * 48?\"}]}\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "- Current time: 2026-01-19 15:13:29 (3:13:29 PM).\n",
      "- Calculation: The current hour is 15, so 100 Ã· 15 = 6.6666666667 (repeating), i.e., 20/3.\n"
     ]
    }
   ],
   "source": [
    "# Test with a multi-step question that requires multiple tool calls\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What time is it, and what is 100 divided by the current hour?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Agent Conversation:\n",
      "==================================================\n",
      "\n",
      "[HUMAN]\n",
      "What time is it, and what is 100 divided by the current hour?\n",
      "\n",
      "[AI]\n",
      "\n",
      "\n",
      "[TOOL]\n",
      "The current date and time is: 2026-01-19 15:13:29\n",
      "\n",
      "[AI]\n",
      "\n",
      "\n",
      "[TOOL]\n",
      "The result of 100 / 15 is 6.666666666666667\n",
      "\n",
      "[AI]\n",
      "- Current time: 2026-01-19 15:13:29 (3:13:29 PM).\n",
      "- Calculation: The current hour is 15, so 100 Ã· 15 = 6.6666666667 (repeating), i.e., 20/3.\n"
     ]
    }
   ],
   "source": [
    "# Let's see the full conversation to understand the agent loop\n",
    "print(\"Full Agent Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in response[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n[{role.upper()}]\")\n",
    "    print(content[:500] if len(str(content)) > 500 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Agent Responses\n",
    "\n",
    "For better UX, we can stream the agent's responses as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Agent Response:\n",
      "==================================================\n",
      "\n",
      "[Node: model]\n",
      "\n",
      "[Node: tools]\n",
      "The result of 0.15 * 250 is 37.5\n",
      "\n",
      "[Node: model]\n",
      "To find 15% of 250, multiply 250 by 0.15:\n",
      "250 Ã— 0.15 = 37.5\n",
      "\n",
      "Answer: 37.5\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's response\n",
    "print(\"Streaming Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in simple_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Calculate 15% of 250\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #1:\n",
    "\n",
    "In the agent loop, what determines whether the agent continues to call tools or returns a final answer to the user? How does `create_agent` handle this decision internally?\n",
    "\n",
    "##### âœ… Answer:\n",
    "In LangChain, the transition from \"thinking/using tools\" to \"responding to the user\" is managed by a ReAct (Reason + Act) pattern. The agent doesn't actually \"know\" it's done, it simply follows a structural protocol until it hits a specific exit condition. If it think it needs more information it will call the tool, if not it will give a final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ Question #2:\n",
    "\n",
    "Looking at the `calculate` and `get_current_time` tools we created, why is the **docstring** so important for each tool? How does the agent use this information when deciding which tool to call?\n",
    "\n",
    "##### âœ… Answer:\n",
    "The docstring is the LLMâ€™s only way to understand the toolâ€™s purpose and logic. \n",
    "\n",
    "It is used as:\n",
    "- Discovery: The agent scans docstrings to match the user's intent to a specific tool.\n",
    "- Syntax: It defines what arguments the model must generate (e.g., \"units must be Celsius\").\n",
    "- Discrimination: It prevents \"tool confusion\" by clarifying when to use one tool over another.\n",
    "- Reliability: Vague docstrings cause hallucinations; precise ones ensure the correct tool is triggered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #1: Create a Custom Tool\n",
    "\n",
    "Create your own custom tool and add it to the agent! \n",
    "\n",
    "Ideas:\n",
    "- A tool that converts temperatures between Celsius and Fahrenheit\n",
    "- A tool that generates a random number within a range\n",
    "- A tool that counts words in a given text\n",
    "\n",
    "Requirements:\n",
    "1. Use the `@tool` decorator\n",
    "2. Include a clear docstring (this is what the agent sees!)\n",
    "3. Add it to the agent and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent updated with Currency Converter!\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts currency between Euro (EUR) and Japanese Yen (JPY).\n",
    "    Use this tool when the user wants to know how much money is worth in EUR or JPY.\n",
    "    Arguments:\n",
    "    - amount: The numerical value to convert.\n",
    "    - from_currency: The currency code you are converting FROM (EUR or JPY).\n",
    "    - to_currency: The currency code you are converting TO (EUR or JPY).\n",
    "    \"\"\"\n",
    "    eur_to_jpy_rate = 183.08\n",
    "    \n",
    "    from_curr = from_currency.upper()\n",
    "    to_curr = to_currency.upper()\n",
    "\n",
    "    if from_curr == \"EUR\" and to_curr == \"JPY\":\n",
    "        result = amount * eur_to_jpy_rate\n",
    "        return f\"{amount} EUR is approximately {result:.2f} JPY.\"\n",
    "    \n",
    "    elif from_curr == \"JPY\" and to_curr == \"EUR\":\n",
    "        result = amount / eur_to_jpy_rate\n",
    "        return f\"{amount} JPY is approximately {result:.2f} EUR.\"\n",
    "    \n",
    "    else:\n",
    "        return \"Error: This tool only supports conversions between EUR and JPY.\"\n",
    "\n",
    "tools = [convert_currency]\n",
    "\n",
    "print(\"Agent updated with Currency Converter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "simple_agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"You are a helpful financial assistant. \n",
    "    Use the convert_currency tool for any money-related questions involving Euros or Yen. \n",
    "    Always explain your reasoning and state the exchange rate used.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(simple_agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "Approximately 9,154 Japanese Yen.\n",
      "\n",
      "Reasoning:\n",
      "- The conversion result indicates 50 EUR â‰ˆ 9,154 JPY.\n",
      "- Implied exchange rate: 9,154 JPY / 50 EUR = 183.08 JPY per EUR.\n",
      "- Calculation: 50 EUR Ã— 183.08 JPY/EUR â‰ˆ 9,154 JPY.\n",
      "\n",
      "Note: Exchange rates fluctuate and may vary at the exact time of your transaction; fees could also affect the final amount.\n"
     ]
    }
   ],
   "source": [
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many Japanese Yen is 50 Euros?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Agent Conversation:\n",
      "==================================================\n",
      "\n",
      "[HUMAN]\n",
      "How many Japanese Yen is 50 Euros?\n",
      "\n",
      "[AI]\n",
      "\n",
      "\n",
      "[TOOL]\n",
      "50.0 EUR is approximately 9154.00 JPY.\n",
      "\n",
      "[AI]\n",
      "Approximately 9,154 Japanese Yen.\n",
      "\n",
      "Reasoning:\n",
      "- The conversion result indicates 50 EUR â‰ˆ 9,154 JPY.\n",
      "- Implied exchange rate: 9,154 JPY / 50 EUR = 183.08 JPY per EUR.\n",
      "- Calculation: 50 EUR Ã— 183.08 JPY/EUR â‰ˆ 9,154 JPY.\n",
      "\n",
      "Note: Exchange rates fluctuate and may vary at the exact time of your transaction; fees could also affect the final amount.\n"
     ]
    }
   ],
   "source": [
    "# Test your custom tool with the agent\n",
    "# Let's see the full conversation to understand the agent loop\n",
    "print(\"Full Agent Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in response[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n[{role.upper()}]\")\n",
    "    print(content[:500] if len(str(content)) > 500 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ¤ Breakout Room #2\n",
    "## Middleware - Agentic RAG with Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the basics of agents, let's build something more powerful: an **Agentic RAG** system.\n",
    "\n",
    "Traditional RAG follows a fixed pattern: retrieve â†’ generate. But **Agentic RAG** gives the agent control over when and how to retrieve information, making it more flexible and intelligent.\n",
    "\n",
    "We'll also introduce **middleware** - hooks that let us customize the agent's behavior at every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Loading & Chunking Documents\n",
    "\n",
    "We'll use the same Health & Wellness Guide from Session 2 to maintain continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Total characters: 16,206\n"
     ]
    }
   ],
   "source": [
    "# Load the document using our aimakerspace utilities\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "\n",
    "# Load the document\n",
    "text_loader = TextFileLoader(\"data/HealthWellnessGuide.txt\")\n",
    "documents = text_loader.load_documents()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Total characters: {sum(len(doc) for doc in documents):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 41 chunks\n",
      "\n",
      "Sample chunk:\n",
      "--------------------------------------------------\n",
      "The Personal Wellness Guide\n",
      "A Comprehensive Resource for Health and Well-being\n",
      "\n",
      "PART 1: EXERCISE AND MOVEMENT\n",
      "\n",
      "Chapter 1: Understanding Exercise Basics\n",
      "\n",
      "Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weigh...\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_texts(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Setting up Qdrant Vector Database\n",
    "\n",
    "Qdrant is a production-ready vector database. We'll use an in-memory instance for development, but the same code works with a hosted Qdrant instance.\n",
    "\n",
    "Key concepts:\n",
    "- **Collection**: A namespace for storing vectors (like a table in SQL)\n",
    "- **Points**: Individual vectors with optional payloads (metadata)\n",
    "- **Distance**: How similarity is measured (we'll use cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NO_PROXY'] = 'openaipublic.blob.core.windows.net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['REQUESTS_CA_BUNDLE'] = 'C:/Users/dznidaric/Documents/certs/cacert.pem'\n",
    "os.environ['SSL_CERT_FILE'] = 'C:/Users/dznidaric/Documents/certs/cacert.pem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: wellness_knowledge_base\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our wellness documents\n",
    "collection_name = \"wellness_knowledge_base\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 41 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store and add documents\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert chunks to LangChain Document objects\n",
    "langchain_docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Create vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(langchain_docs)\n",
    "\n",
    "print(f\"Added {len(langchain_docs)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "--- Document 1 ---\n",
      " memory and learning\n",
      "\n",
      "Chapter 8: Improving Sleep Quality\n",
      "\n",
      "Sleep hygiene refers to habits and practices that promote consistent, quality sleep.\n",
      "\n",
      "Essential sleep hygiene practices:\n",
      "- Maintain a consiste...\n",
      "\n",
      "--- Document 2 ---\n",
      " Avoid caffeine after 2 PM\n",
      "- Exercise regularly, but not too close to bedtime\n",
      "- Limit alcohol and heavy meals before bed\n",
      "\n",
      "Creating an optimal sleep environment:\n",
      "- Temperature: 65-68 degrees Fahrenheit...\n",
      "\n",
      "--- Document 3 ---\n",
      "de for sunlight\n",
      "4. Power pose for 2 minutes\n",
      "5. Healthy snack (nuts, fruit)\n",
      "6. Brief walk around the block\n",
      "7. Upbeat music\n",
      "8. Splash cold water on face\n",
      "\n",
      "Sleep Checklist:\n",
      "- Room temperature 65-68F\n",
      "- Bla...\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "test_results = retriever.invoke(\"How can I improve my sleep?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Creating a RAG Tool\n",
    "\n",
    "Now we'll wrap our retriever as a tool that the agent can use. This is the key to **Agentic RAG** - the agent decides when to retrieve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool created: search_wellness_knowledge\n",
      "Description: Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and ment...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_wellness_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and mental wellness.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Physical health and fitness\n",
    "    - Nutrition and diet\n",
    "    - Sleep and rest\n",
    "    - Mental health and stress management\n",
    "    - General wellness tips\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant wellness information\n",
    "    \"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the wellness knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"Tool created: {search_wellness_knowledge.name}\")\n",
    "print(f\"Description: {search_wellness_knowledge.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Introduction to Middleware\n",
    "\n",
    "**Middleware** in LangChain 1.0 allows you to hook into the agent loop at various points:\n",
    "\n",
    "```\n",
    "                       MIDDLEWARE HOOKS                 \n",
    "                                                        \n",
    "   +--------------+                    +--------------+ \n",
    "   | before_model | --> MODEL CALL --> | after_model  | \n",
    "   +--------------+                    +--------------+ \n",
    "                                                        \n",
    "   +-------------------+                                \n",
    "   | wrap_model_call   |  (intercept and modify calls)  \n",
    "   +-------------------+                                \n",
    "```\n",
    "\n",
    "Common use cases:\n",
    "- **Logging**: Track what the agent is doing\n",
    "- **Guardrails**: Filter or modify inputs/outputs\n",
    "- **Rate limiting**: Control API usage\n",
    "- **Human-in-the-loop**: Pause for human approval\n",
    "\n",
    "LangChain provides middleware through **decorator functions** that hook into specific points in the agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging middleware created!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import before_model, after_model\n",
    "\n",
    "# Track how many model calls we've made\n",
    "model_call_count = 0\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state, runtime):\n",
    "    \"\"\"Called before each model invocation.\"\"\"\n",
    "    global model_call_count\n",
    "    model_call_count += 1\n",
    "    message_count = len(state.get(\"messages\", []))\n",
    "    print(f\"[LOG] Model call #{model_call_count} - Messages in state: {message_count}\")\n",
    "    return None  # Return None to continue without modification\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state, runtime):\n",
    "    \"\"\"Called after each model invocation.\"\"\"\n",
    "    last_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
    "    if last_message:\n",
    "        has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
    "        print(f\"[LOG] After model - Tool calls requested: {has_tool_calls}\")\n",
    "    return None\n",
    "\n",
    "print(\"Logging middleware created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call limit middleware created!\n",
      "  - Thread limit: 10\n",
      "  - Run limit: 5\n"
     ]
    }
   ],
   "source": [
    "# You can also use the built-in ModelCallLimitMiddleware to prevent runaway agents\n",
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "# This middleware will stop the agent after 10 model calls per thread\n",
    "call_limiter = ModelCallLimitMiddleware(\n",
    "    thread_limit=10,  # Max calls per conversation thread\n",
    "    run_limit=5,      # Max calls per single run\n",
    "    exit_behavior=\"end\"  # What to do when limit is reached\n",
    ")\n",
    "\n",
    "print(\"Call limit middleware created!\")\n",
    "print(f\"  - Thread limit: {call_limiter.thread_limit}\")\n",
    "print(f\"  - Run limit: {call_limiter.run_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Building Agentic RAG with Middleware\n",
    "\n",
    "Now let's put it all together: an agentic RAG system with middleware support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellness Agent created with middleware!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Reset the call counter\n",
    "model_call_count = 0\n",
    "\n",
    "# Define our tools - include the RAG tool and the calculator from earlier\n",
    "rag_tools = [\n",
    "    search_wellness_knowledge,\n",
    "    calculate,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "# Create the agentic RAG system with middleware\n",
    "wellness_agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=rag_tools,\n",
    "    system_prompt=\"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. Always search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\",\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        log_after_model,\n",
    "        call_limiter\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Wellness Agent created with middleware!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wellness Agent\n",
      "==================================================\n",
      "[LOG] Model call #1 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'tips for better sleep'}, 'id': 'call_HshQeAzWHj6Twcd3wvNAzatg', 'type': 'tool_call'}]\n",
      "[LOG] Model call #2 - Messages in state: 3\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Here are practical tips for better sleep, based on reputable sleep-hygiene guidance:\n",
      "\n",
      "- Keep a consistent schedule: go to bed and wake up at roughly the same times every day, even on weekends. This helps regulate your body clock. (Source 3)\n",
      "\n",
      "- Create a relaxing pre-bed routine: activities like reading, gentle stretching, or a warm bath can signal your body itâ€™s time to wind down. (Source 3)\n",
      "\n",
      "- Make the sleep environment comfortable: keep the bedroom cool, dark, and quiet. A temperature around 65â€“68Â°F (18â€“20Â°C) is often recommended, and consider blackout curtains or a sleep mask, plus white noise if needed. (Sources 2, 3)\n",
      "\n",
      "- Limit screen time before bed: avoid screens 1â€“2 hours before bed to reduce blue-light exposure that can disrupt sleep. (Source 3)\n",
      "\n",
      "- Watch caffeine and timing: avoid caffeine after about 2 PM. (Sources 1, 2, 3)\n",
      "\n",
      "- Exercise regularly, but not too close to bedtime: regular physical activity supports sleep, but try to finish vigorous exercise a few hours before bed. (Sources 2, 3)\n",
      "\n",
      "- Be mindful of meals and alcohol: limit heavy meals and alcohol in the hours leading up to bedtime. (Sources 2, 3)\n",
      "\n",
      "- Check your bedding: a comfortable mattress and pillows can make a big difference for sleep quality. (Sources 1, 2)\n",
      "\n",
      "If youâ€™d like, tell me about your current sleep routine and any particular sleep obstacles youâ€™re facing, and I can tailor these tips to you.\n"
     ]
    }
   ],
   "source": [
    "# Test the wellness agent\n",
    "print(\"Testing Wellness Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are some tips for better sleep?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query\n",
      "==================================================\n",
      "[LOG] Model call #3 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'stress sleep tips sleep hygiene techniques for sleep difficulties adults'}, 'id': 'call_Dxtpocfr5VudKfS3aJdlJRLU', 'type': 'tool_call'}]\n",
      "[LOG] Model call #4 - Messages in state: 3\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Iâ€™m glad you asked. Hereâ€™s a practical plan based on our wellness guidelines, plus the quick math you asked for.\n",
      "\n",
      "Ideas to help with stress and sleep tonight\n",
      "- Set a consistent sleep schedule: try to go to bed and wake up at about the same times every day, including weekends. (Source: Sleep hygiene basics)\n",
      "- Create a relaxing pre-sleep routine: reading, gentle stretching, or a warm bath can help signal your body itâ€™s time to wind down. (Source: Sleep hygiene basics)\n",
      "- Make your sleep environment comfortable: keep the room cool, dark, and quiet. Aim for about 65â€“68Â°F; use blackout curtains or a sleep mask, and ensure your mattress/pillows are comfortable. (Source: Sleep Checklist)\n",
      "- Limit screens and bright light before bed: avoid screens 1â€“2 hours (or at least 1 hour) before bed. (Source: Sleep hygiene basics)\n",
      "- Watch caffeine and alcohol: avoid caffeine after 2 PM and limit alcohol. (Source: Sleep hygiene basics)\n",
      "- Get regular exercise, but not too close to bedtime: regular movement helps sleep, but timing matters. (Source: Sleep hygiene basics)\n",
      "\n",
      "Quick stress-relief ideas you can try now\n",
      "- Do a two-minute power pose to shift your mindset. (Source: Quick mood-boost tips)\n",
      "- Take a brief walk around the block. (Source: Quick mood-boost tips)\n",
      "- Listen to upbeat music and splash cold water on your face to snap back from stress. (Source: Quick mood-boost tips)\n",
      "- Have a light, healthy snack if youâ€™re hungry before bed. (Source: Quick mood-boost tips)\n",
      "\n",
      "If sleep trouble continues\n",
      "- Consider Cognitive Behavioral Therapy for Insomnia (CBT-I) or other relaxation techniques (e.g., progressive muscle relaxation) as longer-term approaches. (Source: Managing Insomnia)\n",
      "\n",
      "How many hours would 6 hours per night for a week be?\n",
      "- 6 hours/night Ã— 7 nights = 42 hours total.\n",
      "\n",
      "A gentle reminder: many adults aim for about 7â€“9 hours of sleep per night, but individual needs vary. If sleep issues persist for several weeks, it can help to explore CBT-I or speak with a healthcare professional. (Source: Daily Wellness Checklist, Managing Insomnia)\n",
      "\n",
      "If youâ€™d like, I can tailor a simple 1-week sleep plan based on your schedule. How many hours are you normally awake before bed, and whatâ€™s your typical wake time?\n"
     ]
    }
   ],
   "source": [
    "# Test with a more complex query\n",
    "print(\"Testing with complex query\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I'm feeling stressed and having trouble sleeping. What should I do, and if I sleep 6 hours a night for a week, how many total hours is that?\"}]}\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent decision-making (should NOT use RAG)\n",
      "==================================================\n",
      "[LOG] Model call #5 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'calculate', 'args': {'expression': '125 * 8'}, 'id': 'call_sRxbS0tOovcVOgwt8Dl5VXUL', 'type': 'tool_call'}]\n",
      "[LOG] Model call #6 - Messages in state: 3\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "125 Ã— 8 = 1,000.\n"
     ]
    }
   ],
   "source": [
    "# Test the agent's ability to know when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 125 * 8?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Agent\n",
    "\n",
    "The agent created by `create_agent` is built on LangGraph, so we can visualize its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "\n",
    "# This tells the 'requests' library and others to ignore certificate errors\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the agent graph\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(wellness_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"\\nAgent structure:\")\n",
    "    print(wellness_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dznidaric\\Documents\\github\\AIE9\\03_The_Agent_Loop\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grandalf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrandalf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAgent structure:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(wellness_agent.get_graph().draw_ascii())\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'grandalf'"
     ]
    }
   ],
   "source": [
    "import grandalf\n",
    "print(\"\\nAgent structure:\")\n",
    "print(wellness_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #3:\n",
    "\n",
    "How does **Agentic RAG** differ from traditional RAG? What are the advantages and potential disadvantages of letting the agent decide when to retrieve information?\n",
    "\n",
    "##### âœ… Answer:\n",
    "Traditional RAG follows a linear \"retrieve-then-answer\" script, whereas Agentic RAG acts as a researcher that can plan, self-correct, and use multiple tools iteratively. It chooses the best tool for the job, whether that's a database, a calculator, or the internet. Let's say we need two different complex tasks, Agentic RAG can combine multiple tools to get the job done.\n",
    "Disadvantages of agentic RAG is higher cost, longer response time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ Question #4:\n",
    "\n",
    "Looking at the middleware examples (`log_before_model`, `log_after_model`, and `ModelCallLimitMiddleware`), describe a real-world scenario where middleware would be essential for a production agent. What specific middleware hooks would you use and why?\n",
    "\n",
    "##### âœ… Answer: \n",
    "Budget protection and safety compliance - In this scenario, we use middleware to ensure the agent stays within financial limits, respects privacy, and doesn't get stuck in infinite reasoning loops.\n",
    "\n",
    "\n",
    "#### Middleware hooks:\n",
    "\n",
    "- **1.`before_model`**: Input sanitization and budget checks\n",
    "    - calculate the total tokens in the current context\n",
    "    - scan the message user sent for sensitive data (like phone number or private national ID number) and mask them before they ever reach the model provider's servers\n",
    "- **2. `after_model`**: Response validation and loop prevention\n",
    "    - essential for \"sanity checking\" what the AI just produced before the system acts on it\n",
    "    - run a small, fast heuristic to see if the model's output contains restricted phrases or if itâ€™s hallucinating tool names that don't exist\n",
    "    - If log_after_model detects that the agent has called the same RAG tool 5 times with the exact same query, the middleware can force the agent to stop and apologize to the user rather than continuing to loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #2: Enhance the Agentic RAG System\n",
    "\n",
    "Now it's your turn! Enhance the wellness agent by implementing ONE of the following:\n",
    "\n",
    "### Option A: Add a New Tool\n",
    "Create a new tool that the agent can use. Ideas:\n",
    "- A tool that calculates BMI given height and weight\n",
    "- A tool that estimates daily calorie needs\n",
    "- A tool that creates a simple workout plan\n",
    "\n",
    "### Option B: Create Custom Middleware\n",
    "Build middleware that adds new functionality:\n",
    "- Middleware that tracks which tools are used most frequently\n",
    "- Middleware that adds a friendly greeting to responses\n",
    "- Middleware that enforces a response length limit\n",
    "\n",
    "### Option C: Improve the RAG Tool\n",
    "Enhance the retrieval tool:\n",
    "- Add metadata filtering\n",
    "- Implement reranking of results\n",
    "- Add source citations with relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_model\n",
    "def safety_guardrail(state, runtime):\n",
    "    \"\"\"Checks user input for crisis keywords before the LLM processes it.\"\"\"\n",
    "    user_input = state.get(\"messages\", [])[-1].content.lower()\n",
    "    \n",
    "    crisis_keywords = [\"suicide\", \"kill myself\", \"end it all\", \"self-harm\", \"want to die\", \"kms\"]\n",
    "\n",
    "    CRISIS_MESSAGE = \"\"\"It sounds like you're going through a very difficult time. Please know that you are not alone. \n",
    "    In the EU, you can call 112 for emergency services anytime. \n",
    "    You can also call 116 123 (the European emotional support number) to talk to someone who can help. \n",
    "    These services are free, confidential, and available 24/7.\"\"\"\n",
    "    \n",
    "    if any(word in user_input for word in crisis_keywords):\n",
    "        send_alert_to_human_team(user_input)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [{\"role\": \"assistant\", \"content\": CRISIS_MESSAGE}],\n",
    "            \"status\": \"escalated_to_human\",\n",
    "            \"interrupt\": True  # This locks the agent so it won't respond anymore\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def send_alert_to_human_team(message):\n",
    "    # API call to Slack, PagerDuty, or your custom dashboard\n",
    "    print(f\"ALARM: User needs human help. Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tools = [\n",
    "    search_wellness_knowledge,\n",
    "    calculate,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "safety_agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=rag_tools,\n",
    "    middleware=[safety_guardrail, log_before_model, call_limiter],\n",
    "    system_prompt=\"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. Always search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wellness Agent\n",
      "==================================================\n",
      "[LOG] Model call #10 - Messages in state: 1\n",
      "[LOG] Model call #11 - Messages in state: 3\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Here are practical tips for better sleep, based on our sleep resources:\n",
      "\n",
      "- Maintain a consistent sleep and wake time every day (including weekends) to reinforce your body's rhythm. (Source 1)\n",
      "- Create a relaxing bedtime routine to signal to your body that itâ€™s time to wind down. (Source 1)\n",
      "- Optimize your sleep environment:\n",
      "  - Keep the room at about 65â€“68Â°F (18â€“20Â°C). (Source 1)\n",
      "  - Use blackout curtains or a sleep mask to keep things dark. (Source 1)\n",
      "  - Keep the room quiet (consider white noise or earplugs). (Source 3)\n",
      "  - Ensure a comfortable mattress and pillows. (Source 1)\n",
      "- Limit exposure to screens for at least 1 hour before bed. (Source 1)\n",
      "- Avoid caffeine after 2 PM. (Source 3)\n",
      "- Exercise regularly, but donâ€™t do vigorous workouts right before bed. (Source 3)\n",
      "- Limit alcohol and heavy meals close to bedtime. (Source 3)\n",
      "- Get some daylight exposure during the day to help regulate your circadian rhythm. (Source 1)\n",
      "- Include light daytime movement, such as a brief walk, to support overall sleep quality. (Source 1)\n",
      "- If you have ongoing trouble sleeping (insomnia), you can explore strategies described in the insomnia-focused section of our materials. (Source 2)\n",
      "\n",
      "Note: Sleep typically occurs in cycles of about 90 minutes, alternating between REM and non-REM sleep. Understanding this can help you plan wake times that feel more refreshed. (Source 2)\n",
      "\n",
      "If youâ€™d like, tell me your current sleep struggles (trouble falling asleep, staying asleep, or waking too early), and I can tailor these tips to your situation. Iâ€™m here to help!\n"
     ]
    }
   ],
   "source": [
    "# Test your enhanced agent here\n",
    "print(\"Testing Wellness Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = safety_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are some tips for better sleep?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wellness Agent\n",
      "==================================================\n",
      "ALARM: User needs human help. Message: i feel like i want to end it all\n",
      "[LOG] Model call #8 - Messages in state: 2\n",
      "[LOG] Model call #9 - Messages in state: 4\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "I'm really glad you told me how youâ€™re feeling. Iâ€™m here with you, and you donâ€™t have to face this alone.\n",
      "\n",
      "If youâ€™re in the EU, you can:\n",
      "- Call 112 for emergency services anytime.\n",
      "- Call 116 123 for emotional support. These services are free, confidential, and available 24/7.\n",
      "\n",
      "If youâ€™re outside the EU, please contact your local emergency number or a crisis line in your country. If youâ€™re in immediate danger, please seek local emergency help right away.\n",
      "\n",
      "In the moment, you might find these quick relief techniques helpful:\n",
      "- Box breathing: inhale for 4, hold for 4, exhale for 4, hold for 4.\n",
      "- Grounding: Name 5 things you can see, 4 you can hear, 3 you can feel, 2 you can smell, 1 you can taste.\n",
      "- Step outside for fresh air or take a short walk.\n",
      "- Progressive muscle relaxation: tense and release muscle groups from toes upward.\n",
      "\n",
      "Longer-term supports (from our wellness resources): regular exercise, adequate sleep, and staying socially connected can help with stress and mood over time.\n",
      "\n",
      "If youâ€™re comfortable, tell me where youâ€™re located (country or region) so I can point you to the most appropriate resources. Are you safe right now, and is there someone you can reach out to in person or by phone? Iâ€™m here to listen and help you get through this moment.\n"
     ]
    }
   ],
   "source": [
    "# Test your enhanced agent here\n",
    "print(\"Testing Wellness Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = safety_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I feel like I want to end it all\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
